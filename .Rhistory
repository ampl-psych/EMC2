test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
data
pars
debug(run_hyper)
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
data
data_input
rownames(data_input)
rownames(samples_neural)
rownames(samples) <- c(rownames(samples_behav), rownames(samples_neural))
devtools::load_all("~/Documents/UVA/2022/EMC2/")
debug(run_hyper)
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
data_input
devtools::load_all("~/Documents/UVA/2022/EMC2/")
debug(run_hyper)
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
devtools::load_all("~/Documents/UVA/2022/EMC2/")
debug(run_hyper)
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
sampler$n_pars
t(data_input[,,i])
devtools::load_all("~/Documents/UVA/2022/EMC2/")
debug(run_hyper)
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
devtools::load_all("~/Documents/UVA/2022/EMC2/")
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
setwd("~/Documents/UVA/2023")
source("rsp_parallel_new.R")
rsp_mc
samples <- test
idx <- which(samples$samples$stage == "sample")
n_thin <- 4
n_chain <- length(idx)/3
idx <- idx[rep(rep(c(F, rep(T, n_thin - 1)), each = c(n_chain/n_thin)), 3)]
max_factors <- 2
loadings_recov <- aperm(samples$samples$theta_lambda[,1:max_factors,idx, drop = F], c(2,1,3))
lambda_mcmc <- t(matrix(loadings_recov, prod(dim(loadings_recov)[1:2]), dim(loadings_recov)[3]))
expanded <- expand.grid(1:max_factors, 1:(samples$n_pars - sum(samples$nuisance)))
colnames(lambda_mcmc) <- paste0("LambdaV", expanded[,2], "_", expanded[,1])
setwd("~/Documents/UVA/2023")
source("rsp_parallel_new.R")
library(factor.switching)
res <- rsp_mc(lambda_mcmc, n_cores = 5)
plot(res)
res$lambda_hat
group_factors
res_merged <- rsp_mc(lambda_mcmc, n_cores = 5)
plot(res_merged)
load("~/Documents/UVA/2022/EMC2/test_toy.RData")
samples <- merge_samples(samplers)
idx <- which(samples$samples$stage == "sample")
n_thin <- 4
n_chain <- length(idx)/3
idx <- idx[rep(rep(c(F, rep(T, n_thin - 1)), each = c(n_chain/n_thin)), 3)]
max_factors <- 2
loadings_recov <- aperm(samples$samples$theta_lambda[,1:max_factors,idx, drop = F], c(2,1,3))
lambda_mcmc <- t(matrix(loadings_recov, prod(dim(loadings_recov)[1:2]), dim(loadings_recov)[3]))
expanded <- expand.grid(1:max_factors, 1:(samples$n_pars - sum(samples$nuisance)))
colnames(lambda_mcmc) <- paste0("LambdaV", expanded[,2], "_", expanded[,1])
setwd("~/Documents/UVA/2023")
source("rsp_parallel_new.R")
library(factor.switching)
res <- rsp_mc(lambda_mcmc, n_cores = 5)
plot(res)
res$lambda_hat
res_merged$lambda_hat
varimax(lambda, F)
varimax(group_factors, F)
res$lambda_hat
res_merged$lambda_hat
varimax(group_factors, F)$loadings[,]
make_hists <- function(hyper, non_hyper, true, title = "Loadings"){
hyper_df <- data.frame(values = hyper, iteration = 1:length(hyper), name = "hierarchical")
non_hyper_df <- data.frame(values = non_hyper, iteration = 1:length(non_hyper), name = "non-hierarchical")
colnames(hyper_df) <- c("values", "iteration", "name")
colnames(non_hyper_df) <- c("values", "iteration", "name")
true_df <- data.frame(values = true, iteration = 1, name = "true")
df <- rbind(hyper_df, non_hyper_df, true_df)
p <- ggplot(df, aes(values)) +
geom_density(data = subset(df, name %in% c("hierarchical", "non-hierarchical")), aes(fill=name), alpha = .25)+
geom_vline(data = subset(df, !name %in% c("hierarchical", "non-hierarchical")), aes(xintercept = values,
colour = name), linewidth = 1.25, lty = "11") +
ggtitle(title)+
theme_bw()
plot(p)
}
lambda_reordered <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered[,,i] <- matrix(res$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
n_pars <- 7
lambda_reordered <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered[,,i] <- matrix(res$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
lambda_reordered_merged <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered_merged[,,i] <- matrix(res_merged$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
idx <- nrow(res_merged$lambda_reordered_mcmc)
lambda_reordered_merged <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered_merged[,,i] <- matrix(res_merged$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
res$lambda_hat
res_merged$lambda_hat
varimax(group_factors, F)$loadings[,]
lambda_reordered_merged <- lambda_reordered_merged[,c(2,1)]
lambda_reordered <- lambda_reordered[,c(2,1),]
lambda_reordered_merged <- lambda_reordered_merged[,c(2,1),]
vari_lambda <- varimax(group_factors, F)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 1
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
dim(lambda_reordered_merged)
n_pars <- 7
idx <- nrow(res$lambda_reordered_mcmc)
lambda_reordered <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered[,,i] <- matrix(res$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
idx <- nrow(res_merged$lambda_reordered_mcmc)
lambda_reordered_merged <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered_merged[,,i] <- matrix(res_merged$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
lambda_reordered <- lambda_reordered[,c(2,1),]
lambda_reordered_merged <- lambda_reordered_merged[,c(2,1),]
vari_lambda <- varimax(group_factors, F)
R <- 1
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
lambda_reordered
n_pars <- 7
idx <- nrow(res$lambda_reordered_mcmc)
lambda_reordered <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered[,,i] <- matrix(res$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
idx <- nrow(res_merged$lambda_reordered_mcmc)
lambda_reordered_merged <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered_merged[,,i] <- matrix(res_merged$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
lambda_reordered
n_pars <- 7
idx <- 1:nrow(res$lambda_reordered_mcmc)
lambda_reordered <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered[,,i] <- matrix(res$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
idx <- 1:nrow(res_merged$lambda_reordered_mcmc)
lambda_reordered_merged <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered_merged[,,i] <- matrix(res_merged$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
lambda_reordered <- lambda_reordered[,c(2,1),]
lambda_reordered_merged <- lambda_reordered_merged[,c(2,1),]
vari_lambda <- varimax(group_factors, F)
R <- 1
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
vari_lambda <- varimax(group_factors, F)$loadings[,]
R <- 1
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
library(ggplot2)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 2
C <- 1
library(ggplot2)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 3
C <- 1
library(ggplot2)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 4
C <- 1
library(ggplot2)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 5
C <- 1
library(ggplot2)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
mean(abs(res_merged$lambda_hat - vari_lambda))
mean(abs(res$lambda_hat - vari_lambda))
make_hists <- function(hyper, non_hyper, true, title = "Loadings"){
hyper_df <- data.frame(values = hyper, iteration = 1:length(hyper), name = "joint")
non_hyper_df <- data.frame(values = non_hyper, iteration = 1:length(non_hyper), name = "non-joint")
colnames(hyper_df) <- c("values", "iteration", "name")
colnames(non_hyper_df) <- c("values", "iteration", "name")
true_df <- data.frame(values = true, iteration = 1, name = "true")
df <- rbind(hyper_df, non_hyper_df, true_df)
p <- ggplot(df, aes(values)) +
geom_density(data = subset(df, name %in% c("joint", "non-joint")), aes(fill=name), alpha = .25)+
geom_vline(data = subset(df, !name %in% c("joint", "non-joint")), aes(xintercept = values,
colour = name), linewidth = 1.25, lty = "11") +
ggtitle(title)+
theme_bw()
plot(p)
}
R <- 1
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
make_hists <- function(hyper, non_hyper, true, title = "Loadings"){
hyper_df <- data.frame(values = hyper, iteration = 1:length(hyper), name = "joint")
non_hyper_df <- data.frame(values = non_hyper, iteration = 1:length(non_hyper), name = "non-joint")
colnames(hyper_df) <- c("values", "iteration", "name")
colnames(non_hyper_df) <- c("values", "iteration", "name")
true_df <- data.frame(values = true, iteration = 1, name = "true")
df <- rbind(hyper_df, non_hyper_df, true_df)
p <- ggplot(df, aes(values)) +
geom_density(data = subset(df, name %in% c("joint", "non-joint")), aes(fill=name), alpha = .25)+
geom_vline(data = subset(df, !name %in% c("joint", "non-joint")), aes(xintercept = values,
colour = "black"), linewidth = 1.25, lty = "11") +
ggtitle(title)+
theme_bw()
plot(p)
}
R <- 1
C <- 1
library(ggplot2)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
make_hists <- function(hyper, non_hyper, true, title = "Loadings"){
hyper_df <- data.frame(values = hyper, iteration = 1:length(hyper), name = "joint")
non_hyper_df <- data.frame(values = non_hyper, iteration = 1:length(non_hyper), name = "non-joint")
colnames(hyper_df) <- c("values", "iteration", "name")
colnames(non_hyper_df) <- c("values", "iteration", "name")
true_df <- data.frame(values = true, iteration = 1, name = "true")
df <- rbind(hyper_df, non_hyper_df, true_df)
p <- ggplot(df, aes(values)) +
geom_density(data = subset(df, name %in% c("joint", "non-joint")), aes(fill=name), alpha = .25)+
geom_vline(data = subset(df, !name %in% c("joint", "non-joint")), aes(xintercept = values), colour = "black", linewidth = 1.25, lty = "11") +
ggtitle(title)+
theme_bw()
plot(p)
}
R <- 1
C <- 1
library(ggplot2)
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 1
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 2
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 3
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 4
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 5
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 6
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 7
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
means <- res$lambda_hat[,c(2,1)]
means <- res$lambda_hat[,c(2,1)]
means_merged <- res_merged$lambda_hat[,c(2,1)]
means
vari_lambda
means[,2] <- -1*means[,2]
means_merged
means_merged[,2] <- -1*means_merged[,2]
mean(abs(means-vari_lambda))
mean(abs(means_merged-vari_lambda))
R <- 4
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 5
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 6
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 7
C <- 1
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
rm(list = ls())
devtools::load_all("~/Documents/UVA/2022/EMC2/")
# The likelihood of the cognitive model
ll_cog <- function(dadm, x){
# Simple DDM with 2 conditions
out1 <- rtdists::ddiffusion(dadm[dadm$cond == 1, ], a = exp(x["a"]), t0 = exp(x["t0"]),
v = x[1])
out2 <- rtdists::ddiffusion(dadm[dadm$cond == 2, ], a = exp(x["a"]), t0 = exp(x["t0"]),
v = x[3])
out <- c(out1, out2)
bad <- (out<1e-10)|(!is.finite(out))
out[bad] <- 1e-10
return(sum(log(pmax(out, 1e-10))))
}
# The likelihood of the neural activity
ll_MRI <- function(dadm, x){
# The first column is the total BOLD signal
y <- dadm[,1]
# The next set of columns are the individual regions activity
X <- as.matrix(dadm[,2:(ncol(dadm)-2)])
# The first set of parameters are the regressors one for each region
betas <- x[1:(length(x) -1)]
# The last parameter is the standard deviation
sigma <- exp(x[length(x)])
return(max(sum(dnorm(y, mean=X %*% betas, sd = sigma, log = T)), -10000))
}
# Some constants
n_subjects <- 200
n_trials_cog <- 100
n_timepoints_mri <- 100
n_factors <- 2
pars1 <- c("v1", "a", "v2", "t0")
pars2 <- c("MRI_c1", "MRI_c2", "MRI_sd")
group_means <- c(.5, log(1.2), 1, log(0.25), -.3, .5, log(.3)) #a, t0 and neural sd are estimated on log-scale to have support on the natural scale
group_factors <- matrix(c(.4, 0.3,
-.4, .4,
.35, -0.05,
.05, 0.1,
.45, -.05,
.4, -.2,
.1, .25), ncol = n_factors, byrow = T)
rownames(group_factors) <- c(pars1, pars2)
group_resid_variance <- c(.05, .1, .15, .2, .15, .1, .05)
group_cov <- group_factors %*% t(group_factors) + diag(group_resid_variance)
# Inspect our simulated factors
corrplot::corrplot(group_factors, is.corr = F, col.lim = c(-1,1))
# Inspect our simulated correlations matrix
corrplot::corrplot(cov2cor(group_cov), is.corr = T)
# seems reasonable, now make some random effects
random_effects <- mvtnorm::rmvnorm(n_subjects, group_means, group_cov)
colnames(random_effects) <- c(pars1, pars2)
behav_data <- data.frame()
neural_data <- data.frame()
for(sub in 1:n_subjects){
pars_cog <- random_effects[sub,1:4]
pars_mri <- random_effects[sub,5:7]
# Generate 2 difficulty conditions
behav1 <- rtdists::rdiffusion(n_trials_cog/2, a = exp(pars_cog[2]), t0 = exp(pars_cog[4]),
v = pars_cog[1])
behav1$cond <- 1
behav2 <- rtdists::rdiffusion(n_trials_cog/2, a = exp(pars_cog[2]), t0 = exp(pars_cog[4]),
v = pars_cog[3])
behav2$cond <- 2
behav <- rbind(behav1, behav2)
behav$subjects <- sub
behav_data <- rbind(behav_data, behav)
# Just generate some random neural time signal
time_signal <-  mvtnorm::rmvnorm(n_timepoints_mri, mean = rep(0, 2))
BOLD <- rnorm(n_timepoints_mri, mean =
time_signal %*% pars_mri[1:2], sd = exp(pars_mri[3]))
neural <- data.frame(y = BOLD, X = time_signal, subjects = sub)
neural_data <- rbind(neural_data, neural)
}
design1 <- make_design(model = ll_cog, custom_p_vector = pars1)
design2 <- make_design(model = ll_MRI, custom_p_vector = pars2)
samplers <- make_samplers(list(behav_data, neural_data), list(design1, design2), type = "infnt_factor", n_factors = 2)
samplers <- run_emc(samplers, fileName = "test_toy_neural2.RData", cores_per_chain = 4, cores_for_chains = 3, verbose = T, iter = 1000)
getwd()
samplers <- make_samplers(list(behav_data), list(design1), type = "single")
samplers <- run_emc(samplers, fileName = "test_toy_behav2.RData", cores_per_chain = 4, cores_for_chains = 3, verbose = T, iter = 1000)
save(behav_data, neural_data, file = "data_toy2.RData")
samplers <- make_samplers(list(neural_data), list(design2), type = "single")
samplers <- run_emc(samplers, fileName = "test_toy_neural2.RData", cores_per_chain = 4, cores_for_chains = 3, verbose = T, iter = 1000)
plot_chains(samplers)
plot_chains(samplers, selection = "mu")
plot_chains(samplers, subject = 1)
load("~/Documents/UVA/2022/EMC2/test_toy_neural2.RData")
load("~/Documents/UVA/2023/test_toy_neural2.RData")
load("~/Documents/UVA/2023/test_toy_behav2.RData")
samples_behav <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_neural2.RData")
samples_neural <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_behav2.RData")
samples_behav <- merge_samples(samplers)
samples_neural <- samples_neural$samples$alpha[,,samples_neural$samples$stage == "sample"]
samples_behav <- samples_behav$samples$alpha[,,samples_behav$samples$stage == "sample"]
samples <- array(0, dim = c(7, n_subjects, min(dim(samples_neural)[3], dim(samples_behav)[3])))
for(i in 1:3000){
samples[1:4,,i] <- samples_behav[,,i]
samples[5:7,,i] <- samples_neural[,,i]
}
i
N <- min(dim(samples_neural)[3], dim(samples_behav)[3])
samples <- array(0, dim = c(7, n_subjects, N))
for(i in 1:N){
samples[1:4,,i] <- samples_behav[,,i]
samples[5:7,,i] <- samples_neural[,,i]
}
rownames(samples) <- c(rownames(samples_behav), rownames(samples_neural))
devtools::load_all("~/Documents/UVA/2022/EMC2/")
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
samples <- test
idx <- which(samples$samples$stage == "sample")
n_thin <- 4
n_chain <- length(idx)/3
idx <- idx[rep(rep(c(F, rep(T, n_thin - 1)), each = c(n_chain/n_thin)), 3)]
max_factors <- 2
loadings_recov <- aperm(samples$samples$theta_lambda[,1:max_factors,idx, drop = F], c(2,1,3))
lambda_mcmc <- t(matrix(loadings_recov, prod(dim(loadings_recov)[1:2]), dim(loadings_recov)[3]))
expanded <- expand.grid(1:max_factors, 1:(samples$n_pars - sum(samples$nuisance)))
colnames(lambda_mcmc) <- paste0("LambdaV", expanded[,2], "_", expanded[,1])
setwd("~/Documents/UVA/2023")
source("rsp_parallel_new.R")
library(factor.switching)
res_merged <- rsp_mc(lambda_mcmc, n_cores = 5)
plot(res_merged)
load("~/Documents/UVA/2023/test_toy_2.RData")
load("~/Documents/UVA/2023/test_toy_2.RData")
samples <- merge_samples(samplers)
idx <- which(samples$samples$stage == "sample")
n_thin <- 4
n_chain <- length(idx)/3
idx <- idx[rep(rep(c(F, rep(T, n_thin - 1)), each = c(n_chain/n_thin)), 3)]
max_factors <- 2
loadings_recov <- aperm(samples$samples$theta_lambda[,1:max_factors,idx, drop = F], c(2,1,3))
lambda_mcmc <- t(matrix(loadings_recov, prod(dim(loadings_recov)[1:2]), dim(loadings_recov)[3]))
expanded <- expand.grid(1:max_factors, 1:(samples$n_pars - sum(samples$nuisance)))
colnames(lambda_mcmc) <- paste0("LambdaV", expanded[,2], "_", expanded[,1])
setwd("~/Documents/UVA/2023")
source("rsp_parallel_new.R")
library(factor.switching)
res <- rsp_mc(lambda_mcmc, n_cores = 5)
plot(res)
res$lambda_hat
res_merged$lambda_hat
varimax(group_factors, F)$loadings[,]
make_hists <- function(hyper, non_hyper, true, title = "Loadings"){
hyper_df <- data.frame(values = hyper, iteration = 1:length(hyper), name = "joint")
non_hyper_df <- data.frame(values = non_hyper, iteration = 1:length(non_hyper), name = "non-joint")
colnames(hyper_df) <- c("values", "iteration", "name")
colnames(non_hyper_df) <- c("values", "iteration", "name")
true_df <- data.frame(values = true, iteration = 1, name = "true")
df <- rbind(hyper_df, non_hyper_df, true_df)
p <- ggplot(df, aes(values)) +
geom_density(data = subset(df, name %in% c("joint", "non-joint")), aes(fill=name), alpha = .25)+
geom_vline(data = subset(df, !name %in% c("joint", "non-joint")), aes(xintercept = values), colour = "black", linewidth = 1.25, lty = "11") +
ggtitle(title)+
theme_bw()
plot(p)
}
n_pars <- 7
idx <- 1:nrow(res$lambda_reordered_mcmc)
lambda_reordered <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered[,,i] <- matrix(res$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
idx <- 1:nrow(res_merged$lambda_reordered_mcmc)
lambda_reordered_merged <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered_merged[,,i] <- matrix(res_merged$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
res$lambda_hat
res_merged$lambda_hat
varimax(group_factors, F)$loadings[,]
lambda_reordered_merged <- lambda_reordered_merged[,c(2,1),]
vari_lambda <- varimax(group_factors, F)$loadings[,]
library(ggplot2)
R <- 2
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
means <- res$lambda_hat
means_merged <- res_merged$lambda_hat[,c(2,1)]
mean(abs(means-vari_lambda))
mean(abs(means_merged-vari_lambda))
R <- 1
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 3
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
samples_behav
1/samples$samples$theta_sig_err_inv
1/samples$samples$theta_sig_err_inv[1,]
# Sig err inv
load("~/Documents/UVA/2023/test_toy_neural2.RData")
samples_neural <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_behav2.RData")
samples_behav <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_2.RData")
samples <- merge_samples(samplers)
sig_behav <- samples_behav$samples$theta_sig_err_inv[,samples$samples$stage == "sample"]
sig_behav <- samples_behav$samples$theta_sig_err_inv[,samples_behav$samples$stage == "sample"]
make_hists(sig_full[1,], sig_behav[1,], group_resid_variance)
sig_full <- samples$samples$theta_sig_err_inv[,samples$samples$stage == "sample"]
sig_behav <- samples_behav$samples$theta_sig_err_inv[,samples_behav$samples$stage == "sample"]
make_hists(sig_full[1,], sig_behav[1,], group_resid_variance)
sig_full[1,]
1/sig_behav[1,]
sig_full <- samples$samples$theta_sig_err_inv[,samples$samples$stage == "sample"]
sig_merged <- test$samples$theta_sig_err_inv
make_hists(1/sig_full[1,], 1/sig_merged[1,], group_resid_variance)
make_hists(1/sig_full[1,], 1/sig_merged[1,], group_resid_variance[1])
N <- 1
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 2
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 3
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 4
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 5
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 6
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 7
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
